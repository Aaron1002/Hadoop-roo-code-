# Hadoop 與 AI/機器學習應用案例

本指南將說明如何使用 Spark MLlib 和 MNIST 手寫數字資料集進行分類，並說明如何使用 Hadoop 處理大規模數據。

1.  **下載 MNIST 資料集：**

    從以下網址下載 MNIST 資料集：

    *   訓練資料：`http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz`
    *   訓練標籤：`http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz`
    *   測試資料：`http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz`
    *   測試標籤：`http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz`

    將這些檔案下載到本地目錄。

2.  **將 MNIST 資料集上傳到 HDFS：**

    ```bash
    hdfs dfs -mkdir /mnist
    hdfs dfs -put train-images-idx3-ubyte.gz /mnist
    hdfs dfs -put train-labels-idx1-ubyte.gz /mnist
    hdfs dfs -put t10k-images-idx3-ubyte.gz /mnist
    hdfs dfs -put t10k-labels-idx1-ubyte.gz /mnist
    ```

3.  **編寫 Spark MLlib 程式：**

    以下是一個使用 Spark MLlib 進行 MNIST 手寫數字分類的範例：

    ```python
    from pyspark.sql import SparkSession
    from pyspark.ml.classification import LogisticRegression
    from pyspark.ml.evaluation import MulticlassClassificationEvaluator
    from pyspark.ml.feature import VectorAssembler
    from pyspark.sql.functions import col

    # 建立 SparkSession
    spark = SparkSession.builder.appName("MNISTClassification").getOrCreate()

    # 讀取 MNIST 資料集 (需要先將資料集轉換為 CSV 格式)
    # 這裡假設您已經將 MNIST 資料集轉換為 CSV 格式，並且上傳到 HDFS
    train_df = spark.read.csv("hdfs://localhost:9000/mnist/mnist_train.csv", header=True, inferSchema=True)
    test_df = spark.read.csv("hdfs://localhost:9000/mnist/mnist_test.csv", header=True, inferSchema=True)

    # 將特徵轉換為向量
    feature_cols = [col_name for col_name in train_df.columns if col_name != "label"]
    assembler = VectorAssembler(inputCols=feature_cols, outputCol="features")
    train_df = assembler.transform(train_df)
    test_df = assembler.transform(test_df)

    # 建立 Logistic Regression 模型
    lr = LogisticRegression(labelCol="label", featuresCol="features", maxIter=10)

    # 訓練模型
    model = lr.fit(train_df)

    # 進行預測
    predictions = model.transform(test_df)

    # 評估模型
    evaluator = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="accuracy")
    accuracy = evaluator.evaluate(predictions)
    print(f"Accuracy = {accuracy}")

    # 停止 SparkSession
    spark.stop()
    ```

    **注意：**

    *   您需要先將 MNIST 資料集轉換為 CSV 格式，才能使用 Spark 讀取。
    *   您需要根據您的實際情況修改程式碼中的 HDFS 路徑。

4.  **執行 Spark MLlib 程式：**

    將以上程式碼儲存為 `mnist_classification.py`，然後使用以下命令執行：

    ```bash
    spark-submit mnist_classification.py